{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-26T22:08:21.384706Z","iopub.execute_input":"2023-06-26T22:08:21.385170Z","iopub.status.idle":"2023-06-26T22:08:21.404645Z","shell.execute_reply.started":"2023-06-26T22:08:21.385133Z","shell.execute_reply":"2023-06-26T22:08:21.403622Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:08:23.703433Z","iopub.execute_input":"2023-06-26T22:08:23.704108Z","iopub.status.idle":"2023-06-26T22:08:23.759606Z","shell.execute_reply.started":"2023-06-26T22:08:23.704051Z","shell.execute_reply":"2023-06-26T22:08:23.758612Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.drop([\"location\",\"keyword\",'id'],axis=1,inplace=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:09:56.872871Z","iopub.execute_input":"2023-06-26T22:09:56.873256Z","iopub.status.idle":"2023-06-26T22:09:56.885601Z","shell.execute_reply.started":"2023-06-26T22:09:56.873225Z","shell.execute_reply":"2023-06-26T22:09:56.884510Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text  target\n0  Our Deeds are the Reason of this #earthquake M...       1\n1             Forest fire near La Ronge Sask. Canada       1\n2  All residents asked to 'shelter in place' are ...       1\n3  13,000 people receive #wildfires evacuation or...       1\n4  Just got sent this photo from Ruby #Alaska as ...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import (BertTokenizerFast,TFBertTokenizer,BertTokenizer,RobertaTokenizerFast,\n                          DataCollatorWithPadding,TFRobertaForSequenceClassification,TFBertForSequenceClassification,\n                          TFBertModel,create_optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:10:48.131969Z","iopub.execute_input":"2023-06-26T22:10:48.132440Z","iopub.status.idle":"2023-06-26T22:11:00.961183Z","shell.execute_reply.started":"2023-06-26T22:10:48.132404Z","shell.execute_reply":"2023-06-26T22:11:00.960247Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id=\"roberta-base\"\ntokenizer=RobertaTokenizerFast.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:11:53.584001Z","iopub.execute_input":"2023-06-26T22:11:53.584768Z","iopub.status.idle":"2023-06-26T22:11:56.133102Z","shell.execute_reply.started":"2023-06-26T22:11:53.584736Z","shell.execute_reply":"2023-06-26T22:11:56.132137Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c09e6826b7cd4a0c9213a54a11ddcf08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ff99ece22f4773b1f6ec1a36785760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"219307ca8aa044ab8dc8eaad6b93f43c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1291d1764ef430cbbfb8d624e3a31dc"}},"metadata":{}}]},{"cell_type":"code","source":"labels=data.pop('target')","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:16:43.650555Z","iopub.execute_input":"2023-06-26T22:16:43.650920Z","iopub.status.idle":"2023-06-26T22:16:43.656265Z","shell.execute_reply.started":"2023-06-26T22:16:43.650889Z","shell.execute_reply":"2023-06-26T22:16:43.655087Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = tokenizer(data['text'].to_list(),padding=True,truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:31:00.244965Z","iopub.execute_input":"2023-06-26T22:31:00.245664Z","iopub.status.idle":"2023-06-26T22:31:00.934459Z","shell.execute_reply.started":"2023-06-26T22:31:00.245630Z","shell.execute_reply":"2023-06-26T22:31:00.933319Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# tokenized_dataset = tokenizer('hey there',padding=True,truncation=True,max_length=128)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:20:10.366565Z","iopub.execute_input":"2023-06-26T22:20:10.366925Z","iopub.status.idle":"2023-06-26T22:20:10.416037Z","shell.execute_reply.started":"2023-06-26T22:20:10.366895Z","shell.execute_reply":"2023-06-26T22:20:10.415125Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(tokenized_dataset['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:31:04.751697Z","iopub.execute_input":"2023-06-26T22:31:04.752648Z","iopub.status.idle":"2023-06-26T22:31:04.759963Z","shell.execute_reply.started":"2023-06-26T22:31:04.752604Z","shell.execute_reply":"2023-06-26T22:31:04.759029Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'<s>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(tokenized_dataset),\n    labels\n))","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:25:12.680193Z","iopub.execute_input":"2023-06-26T22:25:12.680741Z","iopub.status.idle":"2023-06-26T22:25:22.118183Z","shell.execute_reply.started":"2023-06-26T22:25:12.680708Z","shell.execute_reply":"2023-06-26T22:25:22.117234Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:32:55.935120Z","iopub.execute_input":"2023-06-26T22:32:55.936006Z","iopub.status.idle":"2023-06-26T22:32:55.942598Z","shell.execute_reply.started":"2023-06-26T22:32:55.935963Z","shell.execute_reply":"2023-06-26T22:32:55.941603Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<_TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(85,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(85,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.int64, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"model=TFRobertaForSequenceClassification.from_pretrained(model_id,num_labels=2)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:34:52.418287Z","iopub.execute_input":"2023-06-26T22:34:52.418665Z","iopub.status.idle":"2023-06-26T22:34:59.441468Z","shell.execute_reply.started":"2023-06-26T22:34:52.418636Z","shell.execute_reply":"2023-06-26T22:34:59.440598Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b99e14ba03149d4bf8e6635c16e7e3a"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tf_roberta_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n roberta (TFRobertaMainLayer  multiple                 124055040 \n )                                                               \n                                                                 \n classifier (TFRobertaClassi  multiple                 592130    \n ficationHead)                                                   \n                                                                 \n=================================================================\nTotal params: 124,647,170\nTrainable params: 124,647,170\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n#               loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:43:45.687451Z","iopub.execute_input":"2023-06-26T22:43:45.687802Z","iopub.status.idle":"2023-06-26T22:43:45.705278Z","shell.execute_reply.started":"2023-06-26T22:43:45.687772Z","shell.execute_reply":"2023-06-26T22:43:45.704269Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset.batch(32),\n          epochs=5,\n          batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T22:43:49.068464Z","iopub.execute_input":"2023-06-26T22:43:49.068826Z","iopub.status.idle":"2023-06-26T22:53:29.281177Z","shell.execute_reply.started":"2023-06-26T22:43:49.068798Z","shell.execute_reply":"2023-06-26T22:53:29.280004Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Epoch 1/5\n238/238 [==============================] - 133s 368ms/step - loss: 0.3366 - accuracy: 0.8637\nEpoch 2/5\n238/238 [==============================] - 82s 344ms/step - loss: 0.2776 - accuracy: 0.8985\nEpoch 3/5\n238/238 [==============================] - 82s 344ms/step - loss: 0.2374 - accuracy: 0.9137\nEpoch 4/5\n238/238 [==============================] - 82s 344ms/step - loss: 0.2035 - accuracy: 0.9291\nEpoch 5/5\n238/238 [==============================] - 82s 344ms/step - loss: 0.1708 - accuracy: 0.9415\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7cfe3c633c10>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}