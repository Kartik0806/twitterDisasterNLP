{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-23T19:48:39.855243Z","iopub.execute_input":"2023-06-23T19:48:39.855738Z","iopub.status.idle":"2023-06-23T19:48:39.873688Z","shell.execute_reply.started":"2023-06-23T19:48:39.855701Z","shell.execute_reply":"2023-06-23T19:48:39.872587Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualizing the data","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_df=pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:48:39.898379Z","iopub.execute_input":"2023-06-23T19:48:39.898660Z","iopub.status.idle":"2023-06-23T19:48:39.974213Z","shell.execute_reply.started":"2023-06-23T19:48:39.898636Z","shell.execute_reply":"2023-06-23T19:48:39.973263Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:48:39.976103Z","iopub.execute_input":"2023-06-23T19:48:39.976441Z","iopub.status.idle":"2023-06-23T19:48:39.987606Z","shell.execute_reply.started":"2023-06-23T19:48:39.976411Z","shell.execute_reply":"2023-06-23T19:48:39.986354Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0    4342\n1    3271\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\n!pip install contractions\nimport contractions\nfrom textblob import TextBlob\nimport spacy \nimport re\nimport string","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:48:39.989412Z","iopub.execute_input":"2023-06-23T19:48:39.989746Z","iopub.status.idle":"2023-06-23T19:49:08.717645Z","shell.execute_reply.started":"2023-06-23T19:48:39.989714Z","shell.execute_reply":"2023-06-23T19:49:08.716609Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting contractions\n  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nCollecting textsearch>=0.0.21 (from contractions)\n  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nCollecting anyascii (from textsearch>=0.0.21->contractions)\n  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_tweet_username(df):\n    return re.sub('@[^\\s]+','', df)\n\ndef make_lower(df):\n    return df.lower()\n\ndef cont_exp(df):\n    return contractions.fix(df)\n\ndef make_string(df):\n    return str(df)\n\ndef remove_url(df):\n    return re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , df)\n\ndef remove_email(df):\n    return re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", df)\n\n#Retweets\ndef remove_rt(df):\n    df = str(df)\n    return re.sub(r'\\brt\\b', \"\", df).strip()\n\ndef remove_html(df):\n    return BeautifulSoup(df, 'lxml').get_text().strip()\ndef remove_dots(df):\n    dot_pattern = re.compile(r'\\.{1,}')\n    single_dot = dot_pattern.sub(' ', df)\n    return single_dot\n\ndef remove_special_chars(df):\n    df = re.sub(r'[^\\w]+', \" \", df)\n    df = ' '.join(df.split())\n    \n    return df\n\ndef make_base(df):\n    df = str(df)\n    x_list = []\n    doc = nlp(df)\n\n    for token in doc:\n        lemma = token.lemma_\n        if lemma == '-PRON-' or lemma == 'be':\n            lemma = token.text\n\n        x_list.append(lemma)\n    return ' '.join(x_list)\n\ndef spelling_correction(df):\n    df = TextBlob(df).correct()\n    return df\ndef resub(df):\n    return re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", df)\n\ndef get_clean_data(df):\n    df = remove_url(df)\n    df = remove_email(df)\n#    df = remove_special_chars(df)\n    df = remove_html(df)\n#    df = remove_dots(df)\n#    df = make_base(df)\n#    df = spelling_correction(df).raw_sentences[0]\n    df = make_lower(df)\n    df = make_string(df)\n    df = cont_exp(df)\n    df = remove_rt(df)\n    df = resub(df)                             \n    df = remove_tweet_username(df)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:08.720195Z","iopub.execute_input":"2023-06-23T19:49:08.721015Z","iopub.status.idle":"2023-06-23T19:49:08.733879Z","shell.execute_reply.started":"2023-06-23T19:49:08.720970Z","shell.execute_reply":"2023-06-23T19:49:08.732975Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(get_clean_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:08.735152Z","iopub.execute_input":"2023-06-23T19:49:08.736054Z","iopub.status.idle":"2023-06-23T19:49:10.532237Z","shell.execute_reply.started":"2023-06-23T19:49:08.736023Z","shell.execute_reply":"2023-06-23T19:49:10.531131Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/4114496449.py:25: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  return BeautifulSoup(df, 'lxml').get_text().strip()\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df[\"text\"].to_numpy(),\n                                                                            train_df[\"target\"].to_numpy(),\n                                                                            test_size=0.1) # dedicate 10% of samples to validation set ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:52:43.401152Z","iopub.execute_input":"2023-06-23T19:52:43.401553Z","iopub.status.idle":"2023-06-23T19:52:43.408749Z","shell.execute_reply.started":"2023-06-23T19:52:43.401520Z","shell.execute_reply":"2023-06-23T19:52:43.407738Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n\nfrom sklearn.model_selection import train_test_split\n\ntrainX, valX, trainY, valY = train_test_split(train[\"text\"].to_numpy(),\n                                                                            train[\"target\"].to_numpy(),\n                                                                            test_size=0.1) # dedicate 10% of samples to validation set","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:24:01.740377Z","iopub.execute_input":"2023-06-23T20:24:01.740747Z","iopub.status.idle":"2023-06-23T20:24:01.769265Z","shell.execute_reply.started":"2023-06-23T20:24:01.740716Z","shell.execute_reply":"2023-06-23T20:24:01.768347Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:10.559232Z","iopub.execute_input":"2023-06-23T19:49:10.559543Z","iopub.status.idle":"2023-06-23T19:49:10.570236Z","shell.execute_reply.started":"2023-06-23T19:49:10.559520Z","shell.execute_reply":"2023-06-23T19:49:10.569343Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(6851, 6851, 762, 762)"},"metadata":{}}]},{"cell_type":"markdown","source":"# now we have cleaned data, time for building models\n","metadata":{}},{"cell_type":"markdown","source":"# 1. model RNN, LSTM, GRU, Bidirectional","metadata":{}},{"cell_type":"code","source":"round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:10.571567Z","iopub.execute_input":"2023-06-23T19:49:10.571990Z","iopub.status.idle":"2023-06-23T19:49:10.588317Z","shell.execute_reply.started":"2023-06-23T19:49:10.571960Z","shell.execute_reply":"2023-06-23T19:49:10.586763Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"14"},"metadata":{}}]},{"cell_type":"code","source":"# creating embeddings from tokens\nfrom tensorflow.keras.layers import TextVectorization","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:10.589876Z","iopub.execute_input":"2023-06-23T19:49:10.590202Z","iopub.status.idle":"2023-06-23T19:49:10.595695Z","shell.execute_reply.started":"2023-06-23T19:49:10.590174Z","shell.execute_reply":"2023-06-23T19:49:10.594769Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# a text vectorisation layer on top of the model\nmax_length=14\nmax_vocab_length=10000\ntext_vectorizer=TextVectorization(max_tokens=max_vocab_length,\n                                 output_mode='int',\n                                 output_sequence_length=max_length)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:10.596940Z","iopub.execute_input":"2023-06-23T19:49:10.597500Z","iopub.status.idle":"2023-06-23T19:49:16.157620Z","shell.execute_reply.started":"2023-06-23T19:49:10.597467Z","shell.execute_reply":"2023-06-23T19:49:16.156281Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# fit our data to vectorizer\ntext_vectorizer.adapt(train_sentences)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:53:13.784207Z","iopub.execute_input":"2023-06-23T19:53:13.785193Z","iopub.status.idle":"2023-06-23T19:53:14.464790Z","shell.execute_reply.started":"2023-06-23T19:53:13.785156Z","shell.execute_reply":"2023-06-23T19:53:14.463775Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Get the unique words in the vocabulary\nwords_in_vocab = text_vectorizer.get_vocabulary()\ntop_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\nbottom_5_words = words_in_vocab[-5:] # least common tokens\nprint(f\"Number of words in vocab: {len(words_in_vocab)}\")\nprint(f\"Top 5 most common words: {top_5_words}\") \nprint(f\"Bottom 5 least common words: {bottom_5_words}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.022232Z","iopub.execute_input":"2023-06-23T19:49:17.022957Z","iopub.status.idle":"2023-06-23T19:49:17.060297Z","shell.execute_reply.started":"2023-06-23T19:49:17.022922Z","shell.execute_reply":"2023-06-23T19:49:17.059375Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Number of words in vocab: 10000\nTop 5 most common words: ['', '[UNK]', 'the', 'a', 'to']\nBottom 5 least common words: ['manly', 'manitou', 'manifesting', 'manifestation', 'manhood']\n","output_type":"stream"}]},{"cell_type":"code","source":"# now we have tokens for each text sentence, now time from embeddings\nfrom keras.layers import Embedding\n\nembedding_layer=Embedding(input_dim=max_vocab_length,\n                         output_dim=128,\n                         embeddings_initializer='uniform',\n                         input_length=max_length,\n                         name='Embedding')\n#each sentence is of length 14 and each word is represnted using learnable 128 size vector","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.061666Z","iopub.execute_input":"2023-06-23T19:49:17.062099Z","iopub.status.idle":"2023-06-23T19:49:17.070204Z","shell.execute_reply.started":"2023-06-23T19:49:17.062068Z","shell.execute_reply":"2023-06-23T19:49:17.069194Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import random\n# Get a random sentence from training set\nrandom_sentence = random.choice(train_sentences)\nprint(f\"Original text:\\n{random_sentence}\\\n      \\n\\nEmbedded version:\")\n\n# Embed the random sentence (turn it into numerical representation)\nsample_embed = embedding_layer(text_vectorizer([random_sentence]))\nsample_embed","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.071844Z","iopub.execute_input":"2023-06-23T19:49:17.072520Z","iopub.status.idle":"2023-06-23T19:49:17.198451Z","shell.execute_reply.started":"2023-06-23T19:49:17.072486Z","shell.execute_reply":"2023-06-23T19:49:17.197381Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Original text:\na friend is like blood they are not beside us always. but they come out when we are wounded.      \n\nEmbedded version:\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1, 14, 128), dtype=float32, numpy=\narray([[[ 0.04652433,  0.02060845, -0.04968445, ..., -0.03054878,\n         -0.04232873, -0.00330784],\n        [-0.04634892,  0.00537262, -0.03423559, ...,  0.04979067,\n          0.02523496, -0.04066994],\n        [-0.03076838,  0.01311561,  0.03551148, ...,  0.04038313,\n         -0.02300445,  0.00344958],\n        ...,\n        [ 0.04287304,  0.02265931, -0.01749256, ..., -0.04953734,\n          0.0374471 ,  0.04841968],\n        [-0.01695748, -0.02284133, -0.02001741, ..., -0.04414875,\n         -0.03329112, -0.04970726],\n        [-0.01808946, -0.01030345,  0.0076587 , ...,  0.0194551 ,\n         -0.00089896,  0.02501665]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\n\n# Create tokenization and modelling pipeline\nmodel_0 = Pipeline([\n                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n                    (\"clf\", MultinomialNB()) # model the text\n])\n\n# Fit the pipeline to the training data\nmodel_0.fit(train_sentences, train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.199698Z","iopub.execute_input":"2023-06-23T19:49:17.200447Z","iopub.status.idle":"2023-06-23T19:49:17.397554Z","shell.execute_reply.started":"2023-06-23T19:49:17.200415Z","shell.execute_reply":"2023-06-23T19:49:17.396557Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"model0_preds = model_0.predict(val_sentences)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.398974Z","iopub.execute_input":"2023-06-23T19:49:17.399393Z","iopub.status.idle":"2023-06-23T19:49:17.421435Z","shell.execute_reply.started":"2023-06-23T19:49:17.399361Z","shell.execute_reply":"2023-06-23T19:49:17.420442Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_0.score(val_sentences,val_labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.422680Z","iopub.execute_input":"2023-06-23T19:49:17.423243Z","iopub.status.idle":"2023-06-23T19:49:17.449301Z","shell.execute_reply.started":"2023-06-23T19:49:17.423217Z","shell.execute_reply":"2023-06-23T19:49:17.448395Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.7847769028871391"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef calculate_results(y_true, y_pred):\n  \"\"\"\n  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n  Args:\n  -----\n  y_true = true labels in the form of a 1D array\n  y_pred = predicted labels in the form of a 1D array\n\n  Returns a dictionary of accuracy, precision, recall, f1-score.\n  \"\"\"\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted\" average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.450897Z","iopub.execute_input":"2023-06-23T19:49:17.451237Z","iopub.status.idle":"2023-06-23T19:49:17.459771Z","shell.execute_reply.started":"2023-06-23T19:49:17.451207Z","shell.execute_reply":"2023-06-23T19:49:17.458800Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"naive_model_result=calculate_results(y_true=val_labels,\n                                    y_pred=model0_preds)\nnaive_model_result","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:49:17.464870Z","iopub.execute_input":"2023-06-23T19:49:17.465306Z","iopub.status.idle":"2023-06-23T19:49:17.478266Z","shell.execute_reply.started":"2023-06-23T19:49:17.465280Z","shell.execute_reply":"2023-06-23T19:49:17.477193Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 78.4776902887139,\n 'precision': 0.7990968040759612,\n 'recall': 0.7847769028871391,\n 'f1': 0.7775051802735186}"},"metadata":{}}]},{"cell_type":"markdown","source":"# using GRU and LSTM ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\ninputs=layers.Input(shape=(1,),dtype='string') #inputs are 1D text strings\nx=text_vectorizer(inputs) # convert inputs to numbers\nx=embedding_layer(x) # convert numbers to vectors (output=(1,15,128))\nx=layers.GlobalAveragePooling1D()(x) # output (1,128)\n# x=layers.Dense(64,activation='relu')(x)\noutputs=layers.Dense(1,activation='sigmoid')(x)\nmodel_1=tf.keras.Model(inputs,outputs,name='model_1')","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:11:13.036091Z","iopub.execute_input":"2023-06-23T20:11:13.036523Z","iopub.status.idle":"2023-06-23T20:11:13.097890Z","shell.execute_reply.started":"2023-06-23T20:11:13.036486Z","shell.execute_reply":"2023-06-23T20:11:13.096919Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"model_1.compile(loss='binary_crossentropy',\n               optimizer=tf.keras.optimizers.Adam())","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:11:15.322264Z","iopub.execute_input":"2023-06-23T20:11:15.322975Z","iopub.status.idle":"2023-06-23T20:11:15.336228Z","shell.execute_reply.started":"2023-06-23T20:11:15.322942Z","shell.execute_reply":"2023-06-23T20:11:15.335204Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:58:44.180631Z","iopub.execute_input":"2023-06-23T19:58:44.180999Z","iopub.status.idle":"2023-06-23T19:58:44.214087Z","shell.execute_reply.started":"2023-06-23T19:58:44.180962Z","shell.execute_reply":"2023-06-23T19:58:44.208180Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 1)]               0         \n                                                                 \n text_vectorization (TextVec  (None, 14)               0         \n torization)                                                     \n                                                                 \n Embedding (Embedding)       (None, 14, 128)           1280000   \n                                                                 \n global_average_pooling1d (G  (None, 128)              0         \n lobalAveragePooling1D)                                          \n                                                                 \n dense (Dense)               (None, 1)                 129       \n                                                                 \n=================================================================\nTotal params: 1,280,129\nTrainable params: 1,280,129\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_1.fit(train_sentences,\n           train_labels,\n            epochs=5,\n            validation_data=(val_sentences,val_labels),\n           )","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:11:18.660447Z","iopub.execute_input":"2023-06-23T20:11:18.660923Z","iopub.status.idle":"2023-06-23T20:11:39.950411Z","shell.execute_reply.started":"2023-06-23T20:11:18.660885Z","shell.execute_reply":"2023-06-23T20:11:39.949347Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Epoch 1/5\n215/215 [==============================] - 10s 42ms/step - loss: 0.4506 - val_loss: 0.5110\nEpoch 2/5\n215/215 [==============================] - 3s 14ms/step - loss: 0.2290 - val_loss: 0.5312\nEpoch 3/5\n215/215 [==============================] - 2s 9ms/step - loss: 0.1610 - val_loss: 0.5748\nEpoch 4/5\n215/215 [==============================] - 2s 9ms/step - loss: 0.1268 - val_loss: 0.6254\nEpoch 5/5\n215/215 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.6740\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78462b6db460>"},"metadata":{}}]},{"cell_type":"code","source":"ml=15\nmax_vocab_length=10000\nvec=TextVectorization(max_tokens=max_vocab_length,\n                                 output_mode='int',\n                                 output_sequence_length=ml)\nvec.adapt(trainX)\n\nemb=Embedding(input_dim=max_vocab_length,\n                         output_dim=128,\n                         embeddings_initializer='uniform',\n                         input_length=ml,\n                         name='Embedding')\ninputs=layers.Input(shape=(1,),dtype='string') #inputs are 1D text strings\nx=vec(inputs) # convert inputs to numbers\nx=emb(x) # convert numbers to vectors (output=(1,15,128))\nx=layers.GlobalAveragePooling1D()(x) # output (1,128)\n# x=layers.Dense(1024,activation='relu')(x)\n# x=layers.Dense(256,activation='relu')(x)\noutputs=layers.Dense(1,activation='sigmoid')(x)\nmodel_1_dummy=tf.keras.Model(inputs,outputs,name='model_1')\n\nmodel_1_dummy.compile(loss='binary_crossentropy',\n               optimizer=tf.keras.optimizers.Adam())\n\nmodel_1_dummy.fit(trainX,\n           trainY,\n            epochs=5,\n            validation_data=(valX,valY),\n           )\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:24:32.478171Z","iopub.execute_input":"2023-06-23T20:24:32.478560Z","iopub.status.idle":"2023-06-23T20:24:54.333293Z","shell.execute_reply.started":"2023-06-23T20:24:32.478528Z","shell.execute_reply":"2023-06-23T20:24:54.332135Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Epoch 1/5\n215/215 [==============================] - 11s 45ms/step - loss: 0.6147 - val_loss: 0.5358\nEpoch 2/5\n215/215 [==============================] - 3s 15ms/step - loss: 0.4445 - val_loss: 0.4645\nEpoch 3/5\n215/215 [==============================] - 2s 10ms/step - loss: 0.3497 - val_loss: 0.4366\nEpoch 4/5\n215/215 [==============================] - 1s 6ms/step - loss: 0.2866 - val_loss: 0.4417\nEpoch 5/5\n215/215 [==============================] - 2s 8ms/step - loss: 0.2389 - val_loss: 0.4585\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78462b3584c0>"},"metadata":{}}]},{"cell_type":"code","source":"# cleaned data\nmodel_1_preds_prob=model_1.predict(val_sentences)\nmodel_1_preds = tf.squeeze(tf.round(model_1_preds_prob))\nmodel_1_results = calculate_results(y_true=val_labels, \n                                    y_pred=model_1_preds)\nmodel_1_results","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:07:24.526369Z","iopub.execute_input":"2023-06-23T20:07:24.526749Z","iopub.status.idle":"2023-06-23T20:07:24.656414Z","shell.execute_reply.started":"2023-06-23T20:07:24.526718Z","shell.execute_reply":"2023-06-23T20:07:24.655530Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"24/24 [==============================] - 0s 2ms/step\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 75.8530183727034,\n 'precision': 0.7570566171841299,\n 'recall': 0.7585301837270341,\n 'f1': 0.756583348908012}"},"metadata":{}}]},{"cell_type":"code","source":"# raw data\nmodel_1_preds_prob=model_1_dummy.predict(valX)\nmodel_1_preds = tf.squeeze(tf.round(model_1_preds_prob))\nmodel_1_results = calculate_results(y_true=valY, \n                                    y_pred=model_1_preds)\nmodel_1_results","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:07:27.971546Z","iopub.execute_input":"2023-06-23T20:07:27.971906Z","iopub.status.idle":"2023-06-23T20:07:28.177993Z","shell.execute_reply.started":"2023-06-23T20:07:27.971876Z","shell.execute_reply":"2023-06-23T20:07:28.177080Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"24/24 [==============================] - 0s 2ms/step\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 80.70866141732283,\n 'precision': 0.8072706481168199,\n 'recall': 0.8070866141732284,\n 'f1': 0.8061454577074249}"},"metadata":{}}]},{"cell_type":"markdown","source":"# pre-trained models","metadata":{}},{"cell_type":"code","source":"import tensorflow_hub as hub\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:27:56.836695Z","iopub.execute_input":"2023-06-23T20:27:56.837091Z","iopub.status.idle":"2023-06-23T20:28:13.292296Z","shell.execute_reply.started":"2023-06-23T20:27:56.837057Z","shell.execute_reply":"2023-06-23T20:28:13.291243Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# this model converts each sentence into vector of 512 dimensions, it does not depend on the size of text\n\n# We can use this encoding layer in place of our text_vectorizer and embedding layer\nsentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n                                        input_shape=[], # shape of inputs coming to our model \n                                        dtype=tf.string, # data type of inputs coming to the USE layer\n                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n                                        name=\"USE\") ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:29:42.822306Z","iopub.execute_input":"2023-06-23T20:29:42.823278Z","iopub.status.idle":"2023-06-23T20:29:48.035381Z","shell.execute_reply.started":"2023-06-23T20:29:42.823242Z","shell.execute_reply":"2023-06-23T20:29:48.034388Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# cleaned data\npretrained_model=tf.keras.Sequential()\npretrained_model.add(sentence_encoder_layer)\n# pretrained_model.add(layers.Dense(256,activation='relu'))\n# pretrained_model.add(layers.Dense(64,activation='relu'))\npretrained_model.add(layers.Dense(32,activation='relu'))\npretrained_model.add(layers.Dense(1,activation='sigmoid'))\n\n\npretrained_model.compile(loss='binary_crossentropy',\n                        optimizer=tf.keras.optimizers.Adam(),\n                        metrics=['accuracy'])\npretrained_model.fit(train_sentences,\n            train_labels,\n            epochs=8,\n            validation_data=(val_sentences, val_labels))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:39:56.751216Z","iopub.execute_input":"2023-06-23T20:39:56.751942Z","iopub.status.idle":"2023-06-23T20:40:20.445225Z","shell.execute_reply.started":"2023-06-23T20:39:56.751908Z","shell.execute_reply":"2023-06-23T20:40:20.444498Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Epoch 1/8\n215/215 [==============================] - 4s 14ms/step - loss: 0.5336 - accuracy: 0.7749 - val_loss: 0.4631 - val_accuracy: 0.7677\nEpoch 2/8\n215/215 [==============================] - 3s 12ms/step - loss: 0.4193 - accuracy: 0.8135 - val_loss: 0.4479 - val_accuracy: 0.7953\nEpoch 3/8\n215/215 [==============================] - 3s 12ms/step - loss: 0.4014 - accuracy: 0.8178 - val_loss: 0.4534 - val_accuracy: 0.7953\nEpoch 4/8\n215/215 [==============================] - 3s 12ms/step - loss: 0.3950 - accuracy: 0.8235 - val_loss: 0.4471 - val_accuracy: 0.7992\nEpoch 5/8\n215/215 [==============================] - 3s 12ms/step - loss: 0.3882 - accuracy: 0.8263 - val_loss: 0.4480 - val_accuracy: 0.8110\nEpoch 6/8\n215/215 [==============================] - 3s 12ms/step - loss: 0.3839 - accuracy: 0.8308 - val_loss: 0.4473 - val_accuracy: 0.8071\nEpoch 7/8\n215/215 [==============================] - 3s 13ms/step - loss: 0.3797 - accuracy: 0.8320 - val_loss: 0.4483 - val_accuracy: 0.8045\nEpoch 8/8\n215/215 [==============================] - 3s 15ms/step - loss: 0.3764 - accuracy: 0.8358 - val_loss: 0.4502 - val_accuracy: 0.8031\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78462b010d60>"},"metadata":{}}]},{"cell_type":"code","source":"# raw data\npretrained_model=tf.keras.Sequential()\npretrained_model.add(sentence_encoder_layer)\n# pretrained_model.add(layers.Dense(256,activation='relu'))\npretrained_model.add(layers.Dense(64,activation='relu'))\npretrained_model.add(layers.Dropout(0.3))\npretrained_model.add(layers.Dense(32,activation='relu'))\npretrained_model.add(layers.Dense(1,activation='sigmoid'))\n\n\npretrained_model.compile(loss='binary_crossentropy',\n                        optimizer=tf.keras.optimizers.Adam(),\n                        metrics=['accuracy'])\npretrained_model.fit(trainX,\n            trainY,\n            epochs=5,\n            validation_data=(valX, valY))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:51:58.588773Z","iopub.execute_input":"2023-06-23T20:51:58.589156Z","iopub.status.idle":"2023-06-23T20:52:20.508038Z","shell.execute_reply.started":"2023-06-23T20:51:58.589124Z","shell.execute_reply":"2023-06-23T20:52:20.506753Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Epoch 1/5\n215/215 [==============================] - 5s 17ms/step - loss: 0.5133 - accuracy: 0.7689 - val_loss: 0.4084 - val_accuracy: 0.8268\nEpoch 2/5\n215/215 [==============================] - 3s 12ms/step - loss: 0.4146 - accuracy: 0.8196 - val_loss: 0.4020 - val_accuracy: 0.8241\nEpoch 3/5\n215/215 [==============================] - 3s 12ms/step - loss: 0.3953 - accuracy: 0.8273 - val_loss: 0.3985 - val_accuracy: 0.8241\nEpoch 4/5\n215/215 [==============================] - 3s 12ms/step - loss: 0.3771 - accuracy: 0.8409 - val_loss: 0.4058 - val_accuracy: 0.8176\nEpoch 5/5\n215/215 [==============================] - 3s 12ms/step - loss: 0.3624 - accuracy: 0.8485 - val_loss: 0.4029 - val_accuracy: 0.8189\n","output_type":"stream"},{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78461be2c6d0>"},"metadata":{}}]},{"cell_type":"code","source":"model_6_preds=tf.squeeze(tf.round(pretrained_model.predict(valX)))\nmodel_6_results = calculate_results(valY, model_6_preds)\n\nmodel_6_preds.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:10:41.374170Z","iopub.execute_input":"2023-06-23T21:10:41.374541Z","iopub.status.idle":"2023-06-23T21:10:42.601485Z","shell.execute_reply.started":"2023-06-23T21:10:41.374509Z","shell.execute_reply":"2023-06-23T21:10:42.600369Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"24/24 [==============================] - 1s 15ms/step\n","output_type":"stream"},{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"TensorShape([762])"},"metadata":{}}]},{"cell_type":"markdown","source":"# last model is giving the best result so far, so now we will train it on whole data, and predict on the test data","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n\ntrain_X=data['text']\ntrain_Y=data['target']\n\npretrained_model=tf.keras.Sequential()\npretrained_model.add(sentence_encoder_layer)\n# pretrained_model.add(layers.Dense(256,activation='relu'))\npretrained_model.add(layers.Dense(64,activation='relu'))\npretrained_model.add(layers.Dropout(0.3))\npretrained_model.add(layers.Dense(32,activation='relu'))\npretrained_model.add(layers.Dense(1,activation='sigmoid'))\n\n\npretrained_model.compile(loss='binary_crossentropy',\n                        optimizer=tf.keras.optimizers.Adam(),\n                        metrics=['accuracy'])\npretrained_model.fit(train_X,\n            train_Y,\n            epochs=5)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:53:15.112093Z","iopub.execute_input":"2023-06-23T20:53:15.112497Z","iopub.status.idle":"2023-06-23T20:53:37.093485Z","shell.execute_reply.started":"2023-06-23T20:53:15.112460Z","shell.execute_reply":"2023-06-23T20:53:37.092386Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Epoch 1/5\n238/238 [==============================] - 5s 13ms/step - loss: 0.4996 - accuracy: 0.7739\nEpoch 2/5\n238/238 [==============================] - 3s 12ms/step - loss: 0.4134 - accuracy: 0.8221\nEpoch 3/5\n238/238 [==============================] - 3s 11ms/step - loss: 0.3943 - accuracy: 0.8325\nEpoch 4/5\n238/238 [==============================] - 3s 11ms/step - loss: 0.3812 - accuracy: 0.8358\nEpoch 5/5\n238/238 [==============================] - 3s 11ms/step - loss: 0.3645 - accuracy: 0.8468\n","output_type":"stream"},{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78461ba77580>"},"metadata":{}}]},{"cell_type":"code","source":"test_data=pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntest_data.head()\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:09:03.385229Z","iopub.execute_input":"2023-06-23T21:09:03.386202Z","iopub.status.idle":"2023-06-23T21:09:03.406854Z","shell.execute_reply.started":"2023-06-23T21:09:03.386170Z","shell.execute_reply":"2023-06-23T21:09:03.405926Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"(3263, 4)"},"metadata":{}}]},{"cell_type":"code","source":"test_X=test_data['text']\npred_probablties=pretrained_model.predict(test_X)\npred_probablties.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:08:03.251642Z","iopub.execute_input":"2023-06-23T21:08:03.252390Z","iopub.status.idle":"2023-06-23T21:08:04.602210Z","shell.execute_reply.started":"2023-06-23T21:08:03.252329Z","shell.execute_reply":"2023-06-23T21:08:04.601259Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 1s 10ms/step\n","output_type":"stream"},{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"(3263, 1)"},"metadata":{}}]},{"cell_type":"code","source":"prediction=tf.squeeze(tf.round(pretrained_model.predict(test_X)))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:11:40.148596Z","iopub.execute_input":"2023-06-23T21:11:40.149022Z","iopub.status.idle":"2023-06-23T21:11:41.472234Z","shell.execute_reply.started":"2023-06-23T21:11:40.148981Z","shell.execute_reply":"2023-06-23T21:11:41.471176Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 1s 9ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"test_id=test_data['id']\ntest_id.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:11:52.468001Z","iopub.execute_input":"2023-06-23T21:11:52.468479Z","iopub.status.idle":"2023-06-23T21:11:52.480284Z","shell.execute_reply.started":"2023-06-23T21:11:52.468440Z","shell.execute_reply":"2023-06-23T21:11:52.479005Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"(3263,)"},"metadata":{}}]},{"cell_type":"code","source":"output=pd.DataFrame({'id':test_id, 'target':prediction})\noutput['target']=output['target'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:17:41.368892Z","iopub.execute_input":"2023-06-23T21:17:41.369352Z","iopub.status.idle":"2023-06-23T21:17:41.377583Z","shell.execute_reply.started":"2023-06-23T21:17:41.369316Z","shell.execute_reply":"2023-06-23T21:17:41.376428Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"output.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:17:52.632424Z","iopub.execute_input":"2023-06-23T21:17:52.632803Z","iopub.status.idle":"2023-06-23T21:17:52.641287Z","shell.execute_reply.started":"2023-06-23T21:17:52.632774Z","shell.execute_reply":"2023-06-23T21:17:52.640400Z"},"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T21:17:55.621330Z","iopub.execute_input":"2023-06-23T21:17:55.621713Z","iopub.status.idle":"2023-06-23T21:17:55.635152Z","shell.execute_reply.started":"2023-06-23T21:17:55.621684Z","shell.execute_reply":"2023-06-23T21:17:55.634261Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}